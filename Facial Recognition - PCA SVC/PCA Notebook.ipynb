{
 "metadata": {
  "name": "",
  "signature": "sha256:a03dcea25d6350c3c1dfdeacbd858d178b2f999a3b2f00ad3f8a894e497b662d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Facial Recognition using Eigenfaces and SVMs."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Synopsis\n",
      "In recent years there has been a growing effort to progress how humans and machines interact. Machine learning is continuing to penetrate into technology and our daily lives - from recommender systems that suggest items that you may like, to self driving cars. The end goal of this effort is to effectively automate as many tasks as possible and to achieving a natural interaction with the technology we rely on everyday.\n",
      "\n",
      "Humans recognize faces and interpret emotions from just a glance, with little to no effort. This ability is a result of the evolutionary advantage of being able to extract information from a member of the same species. The advantages of being able to recognize a person's faces in real time from a huge database would give huge benefits to society - police would capture criminals more easily, keys and pass codes may become redundant etc. \n",
      "\n",
      "This is however, a difficult task to implement with an automated system. Facial recognition applications suffer from many drawbacks, especially information lying in high dimensional subspaces, the limitations of training data and how well the model will generalize when given new data. In an attempt to overcome these problems, this notebook uses PCA (principle component analysis) and K-folds cross validation. The dataset used is a preprocessed excerpt of the \"Labeled Faces in the Wild\" dataset from sklearn.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Libraries\n",
      "The following python libraries were used throughout the code."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time\n",
      "import logging\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.datasets import fetch_lfw_people\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.decomposition import RandomizedPCA\n",
      "from sklearn.svm import SVC"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Data Processing\n",
      "The dataset used is a preprocessed excerpt of the \"Labeled Faces in the Wild\" dataset, availble from sklearn at http://vis-www.cs.umass.edu/lfw/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Download the data, if not already on disk and load it as numpy arrays.\n",
      "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Extract the images shape for plotting later.\n",
      "n_samples, height, width = lfw_people.images.shape\n",
      "\n",
      "# Set the random seed for reproducibility.\n",
      "np.random.seed(42)\n",
      "\n",
      "# Get the relevant data.\n",
      "X = lfw_people.data\n",
      "\n",
      "# Get the number of features.\n",
      "n_features = X.shape[1]\n",
      "\n",
      "# The label to predict is the name corresponding to the face.\n",
      "y = lfw_people.target\n",
      "target_names = lfw_people.target_names\n",
      "\n",
      "# The number of different faces.\n",
      "n_classes = target_names.shape[0]\n",
      "\n",
      "print \"Total dataset size:\"\n",
      "print \"n_samples: %d\" % n_samples\n",
      "print \"n_features: %d\" % n_features\n",
      "print \"n_classes: %d\" % n_classes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total dataset size:\n",
        "n_samples: 1217\n",
        "n_features: 1850\n",
        "n_classes: 6\n"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Modelling\n",
      "The data was split into a training and test set 75-25."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Split into a training set and a test set using a stratified k fold.\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A PCA was computed on the dataset in order to reduce the dimensionality of the problem and the compute time required. The number of principal components to keep was set to 300. The higher the number, the more complex the model becomes. This complexity initially increases the accuracy of the model but it eventually hinders it because it overfits on the training data and does not generalize well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Number of principal components.\n",
      "n_components = 300\n",
      "\n",
      "print \"Extracting the top %d eigenfaces from %d faces\" % (n_components, X_train.shape[0])\n",
      "t0 = time()\n",
      "pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\n",
      "print \"done in %0.3fs\" % (time() - t0)\n",
      "\n",
      "# Reshape the pca components in order to plot them later.\n",
      "eigenfaces = pca.components_.reshape((n_components, height, width))\n",
      "\n",
      "print \"Projecting the input data on the eigenfaces orthonormal basis\"\n",
      "t0 = time()\n",
      "X_train_pca = pca.transform(X_train)\n",
      "X_test_pca = pca.transform(X_test)\n",
      "print \"done in %0.3fs\" % (time() - t0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Extracting the top 300 eigenfaces from 912 faces\n",
        "done in 0.829s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Projecting the input data on the eigenfaces orthonormal basis\n",
        "done in 0.099s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Find how much of the variance the first 3 components account for."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print pca.explained_variance_ratio_[0:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.175616    0.15863399  0.07318666]\n"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A support vector machine (SVM) model was trained using the principal components. A radial basis function (RBF) kernel was used. A grid search was set up to find the optimal values for C (the penalty paramenter and gamma (the kernel coefficient)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train a SVM classification model.\n",
      "print \"Fitting the classifier to the training set\"\n",
      "t0 = time()\n",
      "\n",
      "# Set the different parameters for the grid search.\n",
      "param_grid = {\n",
      "         'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
      "          'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
      "          }\n",
      "\n",
      "clf = GridSearchCV(SVC(kernel='rbf', class_weight='auto'), param_grid)\n",
      "clf = clf.fit(X_train_pca, y_train)\n",
      "print \"done in %0.3fs\" % (time() - t0)\n",
      "print \"Best estimator found by grid search:\"\n",
      "print clf.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting the classifier to the training set\n",
        "done in 36.838s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Best estimator found by grid search:\n",
        "SVC(C=1000.0, cache_size=200, class_weight='auto', coef0=0.0, degree=3,\n",
        "  gamma=0.0005, kernel='rbf', max_iter=-1, probability=False,\n",
        "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n"
       ]
      }
     ],
     "prompt_number": 137
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The model was optimized to fit the training set, resulting in a configuration of c = 1000, and gamma = 0.005."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Results\n",
      "Next, the model was given new data to see how well it generalizes. The model's predictions of the classes of test dataset were compared with the actual classes. The results are shown below in a classifcation report and a confusion matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Quantitative evaluation of the model quality on the test set.\n",
      "print \"Predicting the people names on the testing set\"\n",
      "t0 = time()\n",
      "y_pred = clf.predict(X_test_pca)\n",
      "print \"done in %0.3fs\" % (time() - t0)\n",
      "\n",
      "print classification_report(y_test, y_pred, target_names=target_names)\n",
      "print confusion_matrix(y_test, y_pred, labels=range(n_classes))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predicting the people names on the testing set\n",
        "done in 0.113s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                   precision    recall  f1-score   support\n",
        "\n",
        "     Ariel Sharon       0.40      0.43      0.41        14\n",
        "     Colin Powell       0.80      0.74      0.77        65\n",
        "  Donald Rumsfeld       0.74      0.61      0.67        33\n",
        "    George W Bush       0.84      0.92      0.88       133\n",
        "Gerhard Schroeder       0.74      0.74      0.74        23\n",
        "       Tony Blair       0.76      0.70      0.73        37\n",
        "\n",
        "      avg / total       0.78      0.79      0.78       305\n",
        "\n",
        "[[  6   3   3   2   0   0]\n",
        " [  3  48   1  10   0   3]\n",
        " [  2   2  20   6   2   1]\n",
        " [  3   1   0 123   3   3]\n",
        " [  0   2   1   2  17   1]\n",
        " [  1   4   2   3   1  26]]\n"
       ]
      }
     ],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_gallery(images, titles, height, width, n_row=3, n_col=4):\n",
      "    \"\"\"Helper function to plot a gallery of portraits.\"\"\"\n",
      "    \n",
      "    # Set the dimension of the total plot area.\n",
      "    pl.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
      "    \n",
      "    # Set the subplots margins.\n",
      "    pl.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
      "    \n",
      "    # Loop through the rows and columns, plotting the picture, title etc.\n",
      "    for i in range(n_row * n_col):\n",
      "        pl.subplot(n_row, n_col, i + 1)\n",
      "        pl.imshow(images[i].reshape((height, width)), cmap=pl.cm.gray)\n",
      "        pl.title(titles[i], size=12)\n",
      "        pl.xticks(())\n",
      "        pl.yticks(())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def title(y_pred, y_test, target_names, i):\n",
      "    \"\"\"Helper function that outputs formatted precited and true values\"\"\"\n",
      "    \n",
      "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
      "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
      "    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the result of the prediction on a portion of the test set\n",
      "prediction_titles = [title(y_pred, y_test, target_names, i)\n",
      "                     for i in range(y_pred.shape[0])]\n",
      "\n",
      "plot_gallery(X_test, prediction_titles, height, width)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the gallery of the most significant eigenfaces.\n",
      "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
      "plot_gallery(eigenfaces, eigenface_titles, height, width)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import FileLink, FileLinks\n",
      "FileLink('figure_1.png')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<a href='figure_1.png' target='_blank'>figure_1.png</a><br>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 160,
       "text": [
        "C:\\Users\\Chris\\Documents\\GitHub\\ud120-projects\\pca\\figure_1.png"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Eignenfaces is the name given to the resulting eigen vectors when a PCA is carried out in facial recognition. They represent different blends of the original features. The eignenfaces are ordered by importance. Eignfaces are very sensitive to lumination and as a result it's not surprising to see that the first 3 are at the extreme ends of the lighting spectrum. \n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Discussion\n",
      "A precision of 0.79 and a low compute time shows how useful PCA and SVCs are when coupled together in facial reconigition.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}